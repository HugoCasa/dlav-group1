{\rtf1\ansi\ansicpg1252\cocoartf2636
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;\f1\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;\red255\green255\blue255;
\red0\green0\blue0;\red38\green38\blue38;\red234\green235\blue236;}
{\*\expandedcolortbl;;\cssrgb\c0\c1\c1;\cssrgb\c100000\c100000\c100000\c0;\cssrgb\c100000\c100000\c100000;
\cssrgb\c0\c0\c0\c14902;\cssrgb\c20000\c20000\c20000;\cssrgb\c93333\c93725\c94118;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10640\viewh13900\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf2 \cb3 \expnd0\expndtw0\kerning0
\
https://github.com/Kazuhito00/MOT-Tracking-by-Detection-Pipeline\
\
conda install -c anaconda pip \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\pardirnatural\partightenfactor0
\cf2 \kerning1\expnd0\expndtw0 \CocoaLigature0 git clone git@github.com:Kazuhito00/MOT-Tracking-by-Detection-Pipeline.git\
\
\pard\pardeftab720\sa330\partightenfactor0
\cf2 \expnd0\expndtw0\kerning0
\CocoaLigature1 pip install opencv-python\
\pard\pardeftab720\partightenfactor0
\cf2 conda install -c conda-forge onnxruntime\
pip install mediapipe\
pip install filterpy\
conda install -c conda-forge lap \
conda install -c anaconda cython \
pip install cython-bbox
\f1\fs38\fsmilli19200 \cf4 \cb5 \
\pard\pardeftab720\partightenfactor0

\f0\fs32 \cf6 \cb7 conda install -c conda-forge rich 
\f1 \cb1 \

\f0 \cb7 conda install -c conda-forge gdown \
\
conda install -c conda-forge tensorflow=2.4.1
\f1 \cb1 \
\
--device\
Specify camera device number\
Default: 0\
--movie\
Designation of video file *Priority over camera device when specified\
Default: not specified\
--detector\
Model selection for Object Detection\
Any of yolox, efficientdet, ssd, centernet, nanodet, mediapipe_face, mediapipe_hand\
Default: yolox\
--tracker\
Choice of tracking algorithm.\
Any of motpy, bytetrack, mc_bytetrack, norfair, mc_norfair, person_reid, youtureid, sface\
Default: motpy\
--target_id\
Specify the class ID to be tracked.\
If more than one is specified, specify them separated by commas *If None, all are targeted.\
Example: --target_id=1\
Example: --target_id=1,3\
Default: None\
--use_gpu\
Whether GPU inference is used or not\
Default: not specified\
\
}